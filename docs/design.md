# OBJSTORE
_Design doc v.1.00_

## 1.1 Обзор архитектуры — физический уровень

![clusters](clusters.png)

Внутри одного датацентра А создаётся одна или несколько групп физических машин, в каждой группе количество нод 2+ с разной конфигурацией объёма хранения. Разбивка нод по группам происходит на логическом уровне, без изоляции машин друг от друга.


У каждой машины есть локальный IP адрес, все машины должны иметь доступ к интерфейсу Amazon S3, несколько машин могут быть выбраны для подключения внешних клиентов (то есть не обязательно все машины должны быть доступны для подключения по HTTP API, но минимум 1, лучше 2 должны иметь открытый порт).


## 1.2 Обзор архитектуры — логический уровень

На всех нодах запущен бинарь OBJSTORE, через конфиг или аргументы указывается имя кластера, список остальных нод участвующих в системе. Между нодами через пакет astranet  устанавливается виртуальная сеть поверх TCP/IP, она предоставляет P2P discovery механизм, балансировку, роутинг и так далее. В данном случае центрального роутера или реестра нет, каждая нода хранит информацию о других нодах.


При подключении новой ноды, она устанавливает соединение со всеми остальными, во-вторых в системе на уровне AstraNet создаётся общее состояние (таблица маршрутов).


Каждая нода в состоянии обменяться данными с любой другой активной нодой, поэтому как описано в предыдущем случае для доступа к системе достаточно выставить наружу несколько нод, не обязательно все. Каждый инстанс OBJSTORE слушает по HTTP протоколу вызовы API и заворачивает их во внутренний протокол, поэтому каждая нода в состоянии выступить HTTP API фронтендом для всей системы.


Итого, в таблице маршрутов для пяти физических машин имеем:


* cluster-a-node-1 -> 10.0.0.1
* cluster-a-node-2 -> 10.0.0.2
* cluster-a-node-3 -> 10.0.0.3


* cluster-b-node-1 -> 10.0.0.4
* cluster-b-node-2 -> 10.0.0.5


Для ясности я называю ноды натуральными числами, хотя на деле каждая нода при старте назначает себе SHA-1 рандомный. На уровне AstraNet понятия “та же самая нода” не существует, что соответствует реальности — нода, вернувшись после простоя N секунд уже не является той же самой, она является устаревшей и неполноценной.

## 1.3 Обзор архитектуры — итог

Разные конфигурации железа внутри одного ДЦ объединены в виртуальную сеть с внутренним протоколом межсерверного взаимодействия, ноды в сети поддерживают информацию о других нодах в актуальном состоянии и логически разбивают себя в кластеры. Наружу ноды представляют HTTP API и обеспечивают балансировку обработки запросов на основании внутренней карты маршрутов, с поддержкой sticky sessions. При желании ноды могут стучать в Amazon S3.

## 1.4 Обзор архитектуры — FAQ
??? TBD

## 2.1 Журнал событий — внутренности
Каждая нода ведёт свой append-only журнал событий о входящих файлах. Журнал хранится обычным файликом в системе, хранение ключей и значений сделано через BoltDB (или LMDB — начать лучше с BoltDB, но в случае проблем с производительностью не сложно перебраться на LMDB). BoltDB это встраиваемое KV хранилище, которое строит B+-tree индекс, помимо преимуществ вне контекста, для OBJSTORE такой подход полезен, так как два журнала можно очень эффективно сравнить на разницу между собой в 1 проход. А ещё у хранилища есть транзакционность, о ней чуть далее.


Журнал привязывается к сессии, то есть после рестарта существующей ноды она стартует с чистым журналом и кусочком старого. Например: запрос на сохранение файла в OBJSTORE обрабатывается единственной нодой, эта нода пишет в свой журнал под SHA-1 хешом 00000a событие. За час таких событий в журнале 00000a скапливается 100. Затем ноду перезапускают, через час ещё раз, в итоге у ноды через час после третьего запуска в состоянии записано 3 журнала:


* 00000a
* 00000b
* 00000c


Также у ноды есть маппинг мета-данных журналов:


* 00000a -> {00000a, дата создания, дата склейки, первый, последний, кол-во}
* 00000b -> {00000b, дата создания, дата склейки, первый, последний, кол-во}
* 00000c -> {00000c, дата создания, дата склейки, первый, последний, кол-во}


Маппинг нужен при консолидации журналов, например 1 раз в день журналы консолидируются, в качестве основного берётся первый:


* 00000a
   * 00000a (100 элементов) +
   * 00000b (100 элементов) +
   * 00000c (100 элементов)


Поскольку журнал поддерживает транзакционность (см. детали имплементации в начале), то консолидация и одновременное обновление маппинга мета-данных журналов можно выполнить атомарно. Напомню, что все операции на журнале выполняются в append-only режиме и атомарно, поэтому консистентность данных в нём гарантируется.






Новый маппинг:


* 00000a -> {00000a, дата создания, дата склейки, первый, последний, кол-во}
* 00000b -> {00000a, дата создания, дата склейки, первый, последний, кол-во}
* 00000c -> {00000a, дата создания, дата склейки, первый, последний, кол-во}


## 2.2 Журнал событий — синхронизация
Теперь про поведение журналов в контексте, когда нод много, а именно два кластера:


* cluster-a-node-1 -> 10.0.0.1
* cluster-a-node-2 -> 10.0.0.2
* cluster-a-node-3 -> 10.0.0.3


* cluster-b-node-1 -> 10.0.0.4
* cluster-b-node-2 -> 10.0.0.5


### 2.2.1 Событие загрузки


Файл обрабатывается нодой, у каждого файла при загрузке задаётся степень надежности:


1. 1 нода — файл будет храниться только на одной ноде (обрабатывающей запрос);
2. 1 нода + S3 — файл будет храниться на одной ноде и продублирован в S3;
3. Кластер + S3 — файл будет в S3 и отреплицирован всеми нодами в кластере.


Пример: в случае загрузке со степенью надежности 3 на ноду cluster-a-node-1, файл будет записан в S3, в журнал ноды 1 и в журналы остальных нод из кластера А:


* cluster-a-node-2
* cluster-a-node-3


В настройках важно прописать таймаут подключения к остальным нодам в кластере и определить политику, когда считать запрос выполнен успешно. Например: любой запрос с надежностью 2 или 3 считать выполненным успешно при записи в S3, а запись на ноды производить с таймаутом 30 секунд.


В случае переполнения диска на машине, будет отрезана часть журнала с начала, старые файлы удалены, до момента, пока диска не будет хватать. Например, если на машине диск 1GB и лежит 1024 файла по 1мб, то загрузка 512мб удалит 512 файлов и оставит 512 + 1 файл.

### 2.2.2 Событие добавления ноды
Когда нода возвращается в строй, у неё (как подробнее описано в 2.1) может быть прошлое состояние, состоящее из кусочков журналов. Нода должна понять, насколько у неё актуальная инфа и догрузить недостающее. В данном месте консенсус Raft предполагает, что у ноды может быть какая-то новая инфа, но мы не будем спускаться на такой уровень, так как консенсуса тут ещё не хватало.


До того как нода отработает процедуры “о старых событиях” и “о новых событиях”, она не считает себя поднявшейся и запросы не обрабатывает.
О старых журналах
Мы считаем любую возвращённую или новую ноду отсталой и неполноценной, ввиду того что у нас монотонно идущий вперед кеш (с окном истории ~2 месяца) и она должна догонять всех в кластере. Она берёт из своего маппинга журналов 2 события — первое и последнее из каждого журнала. Так как события во всех журналах отсортированы (привет, B+-tree), то используя интервал можно 1 запросом к каждой ноде в кластере понять, есть ли этот фрагмент журнала у них. Пример: у старой ноды 3 журнала, события задаются интервалами 00000a-00000f, 00011a-00011f и 00022a-00022f, она делает 3 x (3 - 1) = 6 запросов к остальным нодам в кластере А и получает в ответ всякую инфу. Поскольку журналы постоянно консолидируются, кол-во запросов и поисков ограничено количеством падений нод.


В случае полного отсутствия этих событий у других нод из кластера мы их херачим прочь с самой ноды, считая устаревшими (вариант новой инфы мы не рассматриваем). Важно! Вариант, когда лишь на 1 ноду писалось очень много файлов со степенью надёжности 1 или 2, а потом она пизданулась и поднялась мы откладываем на полочку идей, потому что теоретически запись идёт через балансировку по нодам и потеря файлов будет не 100%, а 100% / (кол-во нод в кластере), то есть в данном случае потеряется 33% инфы. В случае степени надежности 1 не критично в принципе, в случае надежности 2 — придётся скачать из S3 заново. Для этого придумали степени надежности, используй 3.


В случае частичного отсутствия событий — надо подумать, скорее всего следует урезать журнал на вернувшейся ноде, особенно касается ссылок на другие ноды, когда на других нодах в журнале этих записей больше нет. Урезать сами файлы следует по временному окну (2 месяца). Обработкой нехваткиместа занимается логика при загрузке новых файлов.
О новых журналах
Возвращенная в строй нода должна получить новые журналы от остальных нод в кластере, после чего для всех новых событий она:
1. Для файлов со степенью надежности 1 и 2 создаёт у себя в журнале ссылки на соответствующие ноды, где эти файлы лежат, сами файлы при этом не скачивая;
2. Для файлов со степенью надежности 3 скачивает файл и кладёт себе реплику.


После того как синхронизация завершена, нода объявляет себя активной и готовой обрабатывать запросы.


### 2.2.3 Событие чтения файла
Тут всё просто. Нода, обрабатывающая запрос имеет свои журналы событий, по которым она мгновенно понимает, есть ли у неё запись о файле или нет, затем по этой записи она узнаёт meta-инфу о файле и может ответить сразу. Если спрошен сам файл, то здесь зависит, с каким уровнем надежности он был сохранен, для 3 нода отдаст файл, для остальных перенаправит запрос на ноду, у которой оригинал файла есть.


Если файла у ноды нет, тогда запрос пойдёт в S3, одновременно файл будет отдан из S3, а для ноды будет процесс из раздела 2.2.1. Если файла в кластере н найдено, будут опрошены остальные кластеры, параллельно. Максимальный latency отрицательного ответа — lookup time (<1ms) + ping (<10ms).


## 2.3 Журнал событий — итог

Ноды ведут журналы событий, часть событий это инфа о файлах на ноде, часть это ссылки на другие ноды. Журналы могут быть побиты на куски и склеиваются раз в день. Нода знает границы кусков журналов и может поискать вхождение этих интервалов в журналах других нод, тем самым проверив, насколько актуальная у неё инфа. Нода может скачать себе новые куски журналов, которых у неё нет и синхронизировать файлы - часть записать ссылками на другие ноды, часть скачать с других нод. При переполнении места нода режет себе журнал начиная со старой инфы и удаляет файлы, пока не наберет места для нового файла. В любой момент времени любая нода в любом кластере знает, у кого какие файлы, в итоге когда файл не найден, это значит одно из двух: a) на S3 его тоже нет; b) значит он был сохранён со степенью надежности 1 или 2 и ноды его уже успели удалить.

## 2.4 Журнал событий — FAQ
??? TBD